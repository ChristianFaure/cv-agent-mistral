import streamlit as st
from mistralai import Mistral
import os

# Configuration de la page
st.set_page_config(
    page_title="CV Interactif - [Votre Nom]",
    page_icon="ü§ñ",
    layout="wide"
)

# Initialisation du client Mistral
@st.cache_resource
def get_mistral_client():
    api_key = os.getenv("MISTRAL_API_KEY")
    if not api_key:
        st.error("‚ö†Ô∏è MISTRAL_API_KEY non trouv√©e. V√©rifiez vos secrets Streamlit.")
        st.stop()
    return Mistral(api_key=api_key)

client = get_mistral_client()

# Votre CV et contexte (√† enrichir avec vos vraies donn√©es)
CV_CONTEXT = """
Je suis [VOTRE NOM], candidat pour le poste de Head of Applied AI & Strategic Accounts chez Mistral AI.

## EXP√âRIENCE CL√âS

### OCTO TECHNOLOGY (2012-2024)
- Managing Partner & Directeur Scientifique
- Management de 100 ing√©nieurs sur sujets d'innovation
- Direction de transformations digitales majeures : Accor (refonte moteur r√©servation), 
  Club Med (r√©org tech/produit), Engie (8 plateformes, DDD, DORA), BNP Paribas (priorisation portfolio)
- Directeur Scientifique : 7 th√®ses CIFRE avec INRIA/CEA/CNRS, CIR 1,6M‚Ç¨
- Due diligence tech pour VCs (Criteo, Naxicap, Partech)
- CTO interim chez lesfurets.com

### ATOS/CAPGEMINI (1999-2012)
- Senior Manager sur projets innovation (Web 2.0, API, Agile)

## THOUGHT LEADERSHIP
- Pr√©sident Institut de Recherche et Innovation (Centre Pompidou) 2010-2018
- Membre CA Ars Industrialis (association Bernard Stiegler) 2006-2020
- Co-auteur livre avec Bernard Stiegler sur philosophie de la technique
- Enseignement UTC : Histoire et Prospective des Industries Culturelles

## COMP√âTENCES
- Scaling d'√©quipes tech (20 ‚Üí 100 personnes)
- Transformations B2B grands comptes
- R&D appliqu√©e (th√®ses CIFRE, innovation)
- Philosophie de la technique, √©pist√©mologie
- Vision europ√©enne de l'IA responsable

## MA VISION POUR MISTRAL AI
Je veux structurer l'√©quipe Applied AI avec 3 piliers :
1. OP√âRATIONNEL (50%) : Industrialiser les POCs, cr√©er des playbooks r√©utilisables
2. STRAT√âGIQUE (20%) : D√©velopper des secteurs verticaux (jeux vid√©o, industries culturelles)
3. THOUGHT LEADERSHIP (30%) : Porter la vision europ√©enne de l'IA, relations institutionnelles

Mon atout diff√©renciant : je traduis la technologie de pointe en valeur business B2B.
Je ne suis pas expert ML, mais je sais manager des √©quipes plus expertes que moi et structurer l'adoption.

## R√âALISATIONS QUANTIFIABLES
- 100 ing√©nieurs manag√©s
- 20+ projets de transformation majeurs
- 7 th√®ses CIFRE men√©es √† terme
- Taux satisfaction client >90%
- Pr√©sident institut de recherche public
"""

# Interface utilisateur
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #FF7000 0%, #FF9040 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        margin-bottom: 2rem;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    .user-message {
        background: #f0f0f0;
        border-left: 4px solid #FF7000;
    }
    .assistant-message {
        background: #FFF5ED;
        border-left: 4px solid #FF7000;
    }
</style>
""", unsafe_allow_html=True)

# En-t√™te
st.markdown("""
<div class="main-header">
    <h1>ü§ñ CV Agent Conversationnel</h1>
    <h2>[Votre Nom] - Candidat Head of Applied AI chez Mistral AI</h2>
    <p>Posez-moi n'importe quelle question sur mon parcours, mes comp√©tences ou ma vision pour Mistral AI !</p>
</div>
""", unsafe_allow_html=True)

# Colonnes
col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("üí¨ Conversation")
    
    # Initialisation de l'historique
    if "messages" not in st.session_state:
        st.session_state.messages = []
        # Message de bienvenue
        st.session_state.messages.append({
            "role": "assistant",
            "content": "Bonjour ! Je suis l'agent conversationnel du CV de [Votre Nom]. Je peux r√©pondre √† toutes vos questions sur son parcours, ses comp√©tences, et sa vision pour le poste de Head of Applied AI chez Mistral AI. Que souhaitez-vous savoir ?"
        })
    
    # Affichage de l'historique
    for message in st.session_state.messages:
        css_class = "user-message" if message["role"] == "user" else "assistant-message"
        role_name = "Vous" if message["role"] == "user" else "Agent CV"
        st.markdown(f'<div class="chat-message {css_class}"><strong>{role_name}:</strong> {message["content"]}</div>', 
                   unsafe_allow_html=True)
    
    # Input utilisateur
    user_input = st.chat_input("Posez votre question...")
    
    if user_input:
        # Ajouter message utilisateur
        st.session_state.messages.append({"role": "user", "content": user_input})
        
        # Construire le prompt pour Mistral
        system_prompt = f"""Tu es un assistant qui r√©pond aux questions sur le CV et le profil professionnel d'un candidat.

Contexte du candidat :
{CV_CONTEXT}

Instructions :
- R√©ponds de mani√®re naturelle et conversationnelle
- Utilise "je" pour parler du candidat (tu ES le candidat)
- Sois pr√©cis avec les chiffres et les faits
- Si on te demande quelque chose qui n'est pas dans le contexte, dis-le honn√™tement
- Mets en avant les r√©alisations concr√®tes
- Reste professionnel mais accessible
- Si la question porte sur la motivation pour Mistral AI, explique clairement la proposition de valeur unique
"""
        
        # Pr√©parer les messages pour l'API (nouveau format)
        api_messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # Ajouter l'historique (garder les 6 derniers messages pour le contexte)
        for msg in st.session_state.messages[-6:]:
            api_messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        # Appel √† l'API Mistral (nouvelle syntaxe)
        try:
            with st.spinner("ü§î R√©flexion en cours..."):
                response = client.chat.complete(
                    model="mistral-large-latest",
                    messages=api_messages,
                    temperature=0.7,
                    max_tokens=800
                )
                
                assistant_response = response.choices[0].message.content
                
                # Ajouter la r√©ponse √† l'historique
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": assistant_response
                })
                
                # Rerun pour afficher la nouvelle r√©ponse
                st.rerun()
        
        except Exception as e:
            st.error(f"Erreur : {str(e)}")
            st.info("üí° Astuce : Assurez-vous que MISTRAL_API_KEY est d√©fini dans vos secrets Streamlit")

with col2:
    st.subheader("üìã Actions rapides")
    
    st.markdown("### üí° Questions sugg√©r√©es")
    suggestions = [
        "Quelle est ton exp√©rience en management d'√©quipes tech ?",
        "Pourquoi Mistral AI ?",
        "Quelle serait ta premi√®re action en tant que Head of Applied AI ?",
        "Parle-moi de tes transformations chez OCTO",
        "Comment articules-tu philosophie et technologie ?",
        "Quelle est ta vision du fine-tuning en B2B ?",
        "Que penses-tu du secteur des jeux vid√©o pour Mistral ?",
        "Comment as-tu g√©r√© la R&D chez OCTO ?"
    ]
    
    for suggestion in suggestions:
        if st.button(suggestion, key=suggestion):
            st.session_state.messages.append({"role": "user", "content": suggestion})
            st.rerun()
    
    st.markdown("---")
    st.markdown("### üì• T√©l√©chargements")
    st.button("üìÑ CV PDF complet", help="T√©l√©charger le CV au format PDF")
    st.button("üìß Me contacter", help="Envoyer un email")
    st.button("üîó LinkedIn", help="Voir mon profil LinkedIn")
    
    st.markdown("---")
    st.markdown("### üéØ √Ä propos")
    st.info("""
    Cet agent conversationnel utilise l'API Mistral AI pour r√©pondre 
    √† vos questions sur mon profil professionnel.
    
    **Technologie :**
    - Mod√®le : Mistral Large
    - Framework : Streamlit
    - Contexte : CV + vision strat√©gique
    
    Une d√©monstration concr√®te de ma compr√©hension de l'Applied AI ! üöÄ
    """)
    
    # Statistiques (√† d√©velopper)
    if len(st.session_state.messages) > 1:
        st.markdown("---")
        st.metric("Questions pos√©es", len([m for m in st.session_state.messages if m["role"] == "user"]))
